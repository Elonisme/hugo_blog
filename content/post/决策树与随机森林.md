---
layout:     post
title:      "决策树与随机森林"
date:    2021-07-04T12:00:00
author:     "Elon Li"
image: "/img/post-bg-coffee.jpg"
tags:
    - 机器学习
categories: [ note ]
---


##  决策树

###  什么是决策树？

1. 决策树是一种树状结构，是通过对数据不断的分裂，从而使得数据按照某种规律进行有序分组的一种方式。
2. 现在有一颗古老历经沧桑的千年榕树，决策树的根节点就相当于这颗树的主干，树的主干发端了无数的枝丫，每个枝丫都是数据初步分类的一种类，每一个类里面的数据会再次分类，再次萌发出无数的枝丫，直到无类可分，而决策树的节点就位于这颗千年榕树的每一个分叉的节点，决策树的叶子节点就是枝丫在末端凝结的节点，也是现实生活中树枝枝丫末端的叶子。
3. 决策树的节点的选取，不是人为随意选取的，而是通过某种方式找到能使得原数据进行最低混乱度分类的指标作为节点的。那么什么东西可以衡量一组数据的混乱度？

## 2. 熵

### 什么是熵？

1. 熵是衡量物理世界物理量的混乱度的量，而在这里用来衡量信息的混乱度。而这里我们使用信息熵数据越是整齐划一，信息熵越低。信息熵越低，数据越是统一。

2. 信息熵的数学公式：
                                                                            
   $$
   H(X)=-\sum_{i=1}^{n}p(x_i)log{p(x_i)}
   $$

   1. $H(X)$为一组数据的信息熵
   2. $p(x_i)$是$x_i$归为第$i$​类的概率

## 3. 基尼杂质系数(Gini Impurity)

### 什么是基尼杂质系数？

1. 基尼杂质系数是指所有分类的可能错误率之和。

2. Gini Impurity公式:
   $$
   G=\sum_{i=1}^Cp(i)*[1-p(i)]
   $$

   1. $G$为基尼杂质系数
   2. $C$为类别数
   3. $p(i)$为一个样本归为第$i$类的概率

## 4. 决策树的组织

